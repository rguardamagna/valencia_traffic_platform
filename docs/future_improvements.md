#  Future Improvements - The Chronicler (Ingestion Phase)

This document collects technical improvements identified for the data ingestion phase ("The Chronicler"). These improvements are not blocking for current operations but will elevate the quality, robustness, and maintainability of the project as it scales.

## 1. Code and Ingestion Logic (`src/ingestion/`)

- [ ] **External Configuration:**
    - Move the API URL (`API_URL`) to an environment variable or configuration file (`config.yaml`). Avoid hardcoding.
- [ ] **Storage Efficiency:**
    - Currently, we save JSON with indentation (`indent=2`), which takes up unnecessary space.
    - **Improvement:** Save in **NDJSON** (Newline Delimited JSON) format compressed with **GZIP** (`.json.gz`). This will drastically reduce disk usage on the VPS.
- [ ] **Resilience (Internal Retries):**
    - Implement retry logic within the script (using libraries like `tenacity` or `requests.HTTPAdapter`) to handle network micro-outages without failing the entire Airflow task immediately.
- [ ] **Data Validation (Data Quality):**
    - Add light schema validation (e.g., using `Pydantic` or `Great Expectations`) to ensure the API hasn't changed its format and we aren't saving garbage.

## 2. Orchestration (Airflow DAGs)

- [ ] **Path Portability:**
    - The DAG has the path `/root/valencia_traffic_platform/data` hardcoded.
    - **Improvement:** Use an Airflow Variable (`{{ var.value.project_path }}`) or environment variable so the DAG works in any environment (Dev/Prod) without editing code.
- [ ] **Failure Alerts:**
    - Currently, `email_on_failure` is set to `False`.
    - **Improvement:** Configure notifications to **Telegram** or **Slack** when ingestion fails. (You already have experience with this in the Job Hunter project).
- [ ] **Image Versioning:**
    - The DAG uses `valencia-traffic-ingestion:latest`.
    - **Improvement:** Use specific version tags (e.g., `:v1.0.1`) to ensure immutability and reproducibility.

## 3. Infrastructure and Security

- [ ] **Docker User (Security):**
    - The ingestion container runs as `root` by default (inside the container). It would be ideal to create a non-root user in the `Dockerfile` to improve security.
- [ ] **Data Cleanup (Retention Policy):**
    - There is no deletion policy. The VPS disk will eventually fill up.
    - **Improvement:** Create a maintenance DAG that moves old data (> 30 days) to cheap storage (S3/GCS) or compresses/archives it.

## 4. Testing

- [ ] **Unit Tests:**
    - Create unit tests for `ingest_traffic.py` (mocking the API response) to ensure that saving logic and filenames don't break with future changes.

---
---

#  Mejoras Futuras - The Chronicler (Fase de Ingesti贸n)

Este documento recopila las mejoras t茅cnicas identificadas para la fase de ingesti贸n de datos ("The Chronicler"). Estas mejoras no son bloqueantes para el funcionamiento actual, pero elevar谩n la calidad, robustez y mantenibilidad del proyecto a medida que escale.

## 1. C贸digo y L贸gica de Ingesti贸n (`src/ingestion/`)

- [ ] **Configuraci贸n Externa:**
    - Mover la URL de la API (`API_URL`) a una variable de entorno o archivo de configuraci贸n (`config.yaml`). Evitar hardcoding.
- [ ] **Eficiencia de Almacenamiento:**
    - Actualmente guardamos JSON con indentaci贸n (`indent=2`), lo cual ocupa mucho espacio innecesario.
    - **Mejora:** Guardar en formato **NDJSON** (Newline Delimited JSON) comprimido con **GZIP** (`.json.gz`). Esto reducir谩 dr谩sticamente el uso de disco en el VPS.
- [ ] **Resiliencia (Retries Internos):**
    - Implementar l贸gica de reintento dentro del script (usando librer铆as como `tenacity` o `HTTPAdapter` de `requests`) para manejar micro-cortes de red sin necesidad de fallar toda la tarea de Airflow inmediatamente.
- [ ] **Validaci贸n de Datos (Data Quality):**
    - A帽adir una validaci贸n ligera del esquema de respuesta (ej. usar `Pydantic` o `Great Expectations`) para asegurar que la API no ha cambiado su formato y estamos guardando basura.

## 2. Orquestaci贸n (Airflow DAGs)

- [ ] **Portabilidad de Paths:**
    - El DAG tiene hardcodeada la ruta `/root/valencia_traffic_platform/data`.
    - **Mejora:** Usar una Variable de Airflow (`{{ var.value.project_path }}`) o variable de entorno para que el DAG funcione en cualquier entorno (Dev/Prod) sin editar c贸digo.
- [ ] **Alertas de Fallo:**
    - Actualmente `email_on_failure` est谩 en `False`.
    - **Mejora:** Configurar notificaciones a **Telegram** o **Slack** cuando falle la ingesti贸n. (Ya tienes experiencia con esto en el proyecto Job Hunter).
- [ ] **Versionado de Im谩genes:**
    - El DAG usa `valencia-traffic-ingestion:latest`.
    - **Mejora:** Usar tags de versi贸n espec铆ficos (ej. `:v1.0.1`) para garantizar inmutabilidad y reproducibilidad.

## 3. Infraestructura y Seguridad

- [ ] **Usuario de Docker (Seguridad):**
    - El contenedor de ingesti贸n corre como `root` por defecto (dentro del contenedor). Ser铆a ideal crear un usuario no-root en el `Dockerfile` para mejorar la seguridad.
- [ ] **Limpieza de Datos (Retention Policy):**
    - No hay pol铆tica de borrado. El disco del VPS se llenar谩 eventualmente.
    - **Mejora:** Crear un DAG de mantenimiento que mueva datos antiguos (> 30 d铆as) a un almacenamiento barato (S3/GCS) o los comprima/archive.

## 4. Testing

- [ ] **Unit Tests:**
    - Crear tests unitarios para `ingest_traffic.py` (mockeando la respuesta de la API) para asegurar que la l贸gica de guardado y nombres de archivo no se rompa con cambios futuros.
